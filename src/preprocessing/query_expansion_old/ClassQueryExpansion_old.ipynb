{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ClassQueryExpansion.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1l9v038h4X2o",
        "outputId": "0c3ae7af-d6ff-4bbf-8eeb-e2ea66ece59c"
      },
      "source": [
        "!pip install spacy"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.7/dist-packages (3.0.5)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.8.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (4.41.1)\n",
            "Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from spacy) (3.7.4.3)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.4.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.23.0)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.4.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.19.5)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from spacy) (3.8.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.5)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.5)\n",
            "Requirement already satisfied: pydantic<1.8.0,>=1.7.1 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.7.3)\n",
            "Requirement already satisfied: thinc<8.1.0,>=8.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (8.0.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.11.3)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy) (54.2.0)\n",
            "Requirement already satisfied: typer<0.4.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.3.2)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.2)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (20.9)\n",
            "Requirement already satisfied: smart-open<4.0.0,>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy) (3.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->spacy) (3.4.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy) (1.1.1)\n",
            "Requirement already satisfied: click<7.2.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.4.0,>=0.3.0->spacy) (7.1.2)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy) (2.4.7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eiM3uE574jJE",
        "outputId": "d9a3162c-0483-4277-a9ea-9da35ee72f69"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ofd1_jyo66qm",
        "outputId": "2b7a1e71-5bef-4dca-d600-9b916348a5cb"
      },
      "source": [
        "!unzip -u \"/content/drive/MyDrive/Colab_Notebooks/s2v_reddit_2015_md.zip\" -d \"/content\""
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/drive/MyDrive/Colab_Notebooks/s2v_reddit_2015_md.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pZeSKmYP4ZVH",
        "outputId": "6d319e7b-2c14-46c0-8d18-e1e6d2a5ac75"
      },
      "source": [
        "!pip install sense2vec"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sense2vec in /usr/local/lib/python3.7/dist-packages (2.0.0)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from sense2vec) (2.4.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from sense2vec) (1.19.5)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from sense2vec) (2.0.1)\n",
            "Requirement already satisfied: spacy<4.0.0,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from sense2vec) (3.0.5)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from sense2vec) (0.8.2)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from sense2vec) (3.8.1)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>=3.0.0->sense2vec) (0.4.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>=3.0.0->sense2vec) (2.0.5)\n",
            "Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>=3.0.0->sense2vec) (3.7.4.3)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>=3.0.0->sense2vec) (1.0.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>=3.0.0->sense2vec) (2.23.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>=3.0.0->sense2vec) (54.2.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>=3.0.0->sense2vec) (20.9)\n",
            "Requirement already satisfied: typer<0.4.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>=3.0.0->sense2vec) (0.3.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>=3.0.0->sense2vec) (2.11.3)\n",
            "Requirement already satisfied: thinc<8.1.0,>=8.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>=3.0.0->sense2vec) (8.0.2)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>=3.0.0->sense2vec) (3.0.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>=3.0.0->sense2vec) (3.0.2)\n",
            "Requirement already satisfied: pydantic<1.8.0,>=1.7.1 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>=3.0.0->sense2vec) (1.7.3)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>=3.0.0->sense2vec) (0.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>=3.0.0->sense2vec) (4.41.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->sense2vec) (3.4.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.0.0->sense2vec) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.0.0->sense2vec) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.0.0->sense2vec) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.0.0->sense2vec) (2020.12.5)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy<4.0.0,>=3.0.0->sense2vec) (2.4.7)\n",
            "Requirement already satisfied: click<7.2.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.4.0,>=0.3.0->spacy<4.0.0,>=3.0.0->sense2vec) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy<4.0.0,>=3.0.0->sense2vec) (1.1.1)\n",
            "Requirement already satisfied: smart-open<4.0.0,>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy<4.0.0,>=3.0.0->sense2vec) (3.0.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nU3aF8xk4fCd",
        "outputId": "b1f637c4-92f6-4edb-ca62-5e0b2e49d0ef"
      },
      "source": [
        "!python -m spacy download en_core_web_md"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-04-03 00:28:52.585036: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "Requirement already satisfied: en-core-web-md==3.0.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_md-3.0.0/en_core_web_md-3.0.0-py3-none-any.whl#egg=en_core_web_md==3.0.0 in /usr/local/lib/python3.7/dist-packages (3.0.0)\n",
            "Requirement already satisfied: spacy<3.1.0,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from en-core-web-md==3.0.0) (3.0.5)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (0.4.0)\n",
            "Requirement already satisfied: pydantic<1.8.0,>=1.7.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (1.7.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (2.4.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (0.8.2)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (2.0.5)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (0.4.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (54.2.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (3.0.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (4.41.1)\n",
            "Requirement already satisfied: thinc<8.1.0,>=8.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (8.0.2)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (3.8.1)\n",
            "Requirement already satisfied: typer<0.4.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (0.3.2)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (2.0.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (1.19.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (1.0.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (2.11.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (20.9)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (3.0.2)\n",
            "Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (3.7.4.3)\n",
            "Requirement already satisfied: smart-open<4.0.0,>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (3.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (3.4.1)\n",
            "Requirement already satisfied: click<7.2.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.4.0,>=0.3.0->spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (7.1.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (1.24.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (1.1.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (2.4.7)\n",
            "\u001b[38;5;2mâœ” Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_md')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M88ATkqs9LKh",
        "outputId": "f844da26-c84a-4b03-f029-fb539a7ad45f"
      },
      "source": [
        "!pip install nltk"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uolaOjDcOCXA",
        "outputId": "07706ecb-7ec3-4f7a-f6a7-ca9717c81512"
      },
      "source": [
        "!pip install pandas"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.1.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.1)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from pandas) (1.19.5)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LVmheE4U9Yo3",
        "outputId": "eb33bfa5-ace2-4181-9a6d-eed843a5afc8"
      },
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "from nltk.corpus import  wordnet\n",
        "from typing import List\n",
        "import spacy\n",
        "#en_core_web_md\n",
        "import string\n",
        "from nltk.corpus import wordnet\n",
        "from spacy.lang.en.stop_words import STOP_WORDS\n",
        "import random\n",
        "import numpy as np\n",
        "from itertools import chain\n",
        "\n",
        "#packages to find similar words by wordembedding and sense2vec\n",
        "from sense2vec import Sense2VecComponent \n",
        "from sense2vec import Sense2Vec #for standalone\n",
        "import pandas as pd"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jlTrnvPV4tnd"
      },
      "source": [
        " #!/usr/bin/python\n",
        "\n",
        "\n",
        "#global tags\n",
        "\n",
        "class QueryExpansion:\n",
        "\n",
        "    def __init__(self, query: List[str], top_syns: int = 5, top_similar: int=2):\n",
        "        self.original_query = query\n",
        "        self.nlp = spacy.load(\"en_core_web_md\")\n",
        "        self.top_syns = top_syns\n",
        "\n",
        "        self.sense = self.nlp.add_pipe(\"sense2vec\").from_disk(\"s2v_reddit_2015_md/s2v_old\")\n",
        "        self.standalone_sense = Sense2Vec().from_disk(\"./s2v_reddit_2015_md/s2v_old\") #it is not dubplicated\n",
        "        \n",
        "        self.tags = ['CD','JJ','RB', 'NN', 'NNS','NNP','NNPS', 'VB']\n",
        "        self.pos_tags = ['PROPN','VERB','NOUN','NUM']\n",
        "\n",
        "        self.top_similar = top_similar\n",
        "\n",
        "    # Query Expansion\n",
        "    def expansion(self, original: bool = True, relation: bool = False, synonyms: bool = False, sensevec: bool=False, embedded: bool=False):\n",
        "        result = []\n",
        "        turnOn = 0\n",
        "        if original:\n",
        "            original_queries = [('original', query) for query in self.original_query]\n",
        "            result = [*result, *original_queries]\n",
        "            turnOn = turnOn + 1\n",
        "        #print(turnOn)\n",
        "        if relation:\n",
        "            \n",
        "            new_queries = self.get_comparation_superlation_nouns_from_original_data()\n",
        "            i = turnOn\n",
        "            for new_query in new_queries:\n",
        "              result.insert(i, ('annotation', new_query))\n",
        "              i = i + 1 + turnOn\n",
        "            turnOn = turnOn + 1\n",
        "\n",
        "        if synonyms:\n",
        "            new_queries = self.synonyms()\n",
        "            i = turnOn\n",
        "            for new_query in new_queries:\n",
        "              result.insert(i, ('syns',new_query))\n",
        "              i = i + 1 + turnOn\n",
        "            turnOn = turnOn + 1\n",
        "            \n",
        "            #result = [*result, *self.synonyms()]\n",
        "        \n",
        "        if sensevec:\n",
        "            #result = [*result, *self.similarwords_sensevec()] #each topic there are multi expanded queries by similar words because of replacing methods\n",
        "            new_queries = self.similarwords_sensevec()\n",
        "            i = turnOn\n",
        "            \n",
        "            for queries in new_queries:\n",
        "              #print(queries)\n",
        "              length = len(queries)\n",
        "              #print(length)\n",
        "              index = 1 #for tag sensevec\n",
        "              for query in queries:\n",
        "                #print(query)\n",
        "                result.insert(i, ('sensevec_'+str(index),query))\n",
        "                i = i + 1\n",
        "                index = index + 1\n",
        "              i = i + turnOn\n",
        "              #print(i)\n",
        "            turnOn = turnOn + 1\n",
        "\n",
        "        if embedded:\n",
        "            #result = [*result, *self.similarwords_wordembedding()]\n",
        "            new_queries = self.similarwords_wordembedding()\n",
        "            i = turnOn\n",
        "            \n",
        "            for queries in new_queries:\n",
        "              #print(queries)\n",
        "              length = len(queries)\n",
        "              #print(length)\n",
        "              index = 1 #for tag sensevec\n",
        "              for query in queries:\n",
        "                #print(query)\n",
        "                result.insert(i, ('embedded_'+str(index),query))\n",
        "                i = i + 1\n",
        "                index = index + 1\n",
        "              i = i + turnOn\n",
        "              #print(i)\n",
        "            turnOn = turnOn + 1\n",
        "\n",
        "        #cover to dataframe\n",
        "        df = self.dfCover(result)\n",
        "        return df\n",
        "    def dfCover(self, expansion_result):\n",
        "        df = pd.DataFrame()\n",
        "        indices=[]\n",
        "        #make original col\n",
        "        for e in expansion_result:\n",
        "          if e[0]=='original':\n",
        "            indices.append((expansion_result.index(e), e[1]))\n",
        "        topics = []\n",
        "        for i in range(0,len(indices)-1):\n",
        "          n = indices[i+1][0] - indices[i][0]\n",
        "          #print(n)\n",
        "          topic = indices[i][1]\n",
        "          #print(topic)\n",
        "          topics.append(n * [topic])\n",
        "        #\n",
        "        last_index = indices[-1][0]\n",
        "        last_topic = indices[-1][1]\n",
        "        last_n = len(expansion_result[last_index:])\n",
        "        topics.append(last_n * [last_topic])\n",
        "\n",
        "        #merging\n",
        "        topics = list(chain.from_iterable(topics))\n",
        "        #print(\"check length\")\n",
        "        #print(len(topics))\n",
        "        #print(len(expansion_result))\n",
        "        #expansion in dataframe\n",
        "        df['topic'] = topics\n",
        "        df['expansions'] = expansion_result\n",
        "        df['query'] = [e[1] for e in expansion_result]\n",
        "        df['tag'] = [e[0] for e in expansion_result]\n",
        "        return df\n",
        "\n",
        "    def similarwords_replace(self, query, similar_words):\n",
        "        import copy\n",
        "        expanded_queries=[]\n",
        "        for word, similar_words in similar_words.items():\n",
        "            for similar_word in similar_words:\n",
        "                new_query=copy.deepcopy(query).replace(word, similar_word)\n",
        "                expanded_queries.append(new_query)\n",
        "        return expanded_queries\n",
        "\n",
        "    def similarwords_wordembedding(self):\n",
        "        result = []\n",
        "        for query in self.original_query:\n",
        "            doc = self.nlp(query)\n",
        "            #expanded queries\n",
        "            expanded_queries=[]\n",
        "            similar_words={}\n",
        "            for token in doc:\n",
        "                top_similar_words=[]\n",
        "                if token.tag_ in self.tags or token.pos_ in self.pos_tags:\n",
        "                    if token.lemma_ not in STOP_WORDS or token.text not in STOP_WORDS:\n",
        "                        try:\n",
        "                            word=token.lemma_\n",
        "                            #print(word)\n",
        "                            ms = self.nlp.vocab.vectors.most_similar(np.asarray([self.nlp.vocab.vectors[self.nlp.vocab.strings[word]]]), n=self.top_similar)\n",
        "                            #print(ms)\n",
        "                            similar_embedding = [self.nlp.vocab.strings[w] for w in ms[0][0]] #get only text from most_similar\n",
        "                            \n",
        "                            #checking again if similar words are the same word\n",
        "                            for word in similar_embedding:\n",
        "                                if (word != token.text) and (self.nlp(word)[0].lemma_ != token.lemma_):\n",
        "                                    top_similar_words.append(self.nlp(word)[0].lemma_.lower())\n",
        "                        except ValueError as err:\n",
        "                            print(err)\n",
        "                        \n",
        "                        similar_words[token.text]=list(set(top_similar_words)) #only unique words\n",
        "            \n",
        "            #replace with similar words for new queries.\n",
        "            expanded_queries = self.similarwords_replace(query, similar_words)\n",
        "            result.append(expanded_queries)\n",
        "        return result\n",
        "        \n",
        "    def similarwords_sensevec(self):\n",
        "        result=[]\n",
        "        for query in self.original_query:\n",
        "            doc = self.nlp(query)\n",
        "            expanded_queries=[]\n",
        "            similar_words={}\n",
        "            for token in doc:\n",
        "                top_similar_words=[]\n",
        "                if token.tag_ in self.tags or token.pos_ in self.pos_tags:\n",
        "                    if token.lemma_ not in STOP_WORDS or token.text not in STOP_WORDS:\n",
        "                        try:\n",
        "                            for e in token._.s2v_most_similar(self.top_similar):\n",
        "                                word = e[0][0].strip() #get only word from ((word, tag), proba)\n",
        "                                if (word != token.text) and (self.nlp(word)[0].lemma_ != token.lemma_):\n",
        "                                    top_similar_words.append(word)\n",
        "                        except ValueError as err:\n",
        "                            for ent in doc.ents:\n",
        "                                if ent.text == token.text:\n",
        "                                    try:\n",
        "                                        for e in ent._.s2v_most_similar(self.top_similar):\n",
        "                                            word = e[0][0].strip() #get only word from ((word, tag), proba)\n",
        "                                            if (word != token.text) and (self.nlp(word)[0].lemma_ != token.lemma_):\n",
        "                                                top_similar_words.append(word)\n",
        "\n",
        "                                    except ValueError as err:\n",
        "                                        \n",
        "                                        query = token._.s2v_other_senses[0] #get first similar words by entity_tag\n",
        "                                        for e in self.standalone_s2v.most_similar(query, n=self.top_similar):\n",
        "                                            word = e[0].split(\"|\")[0].strip() #get only word from (word|tag, proba)\n",
        "                                            if (word != token.text) and (self.nlp(word)[0].lemma_ != token.lemma_):\n",
        "                                                top_similar_words.append(word)\n",
        "                        \n",
        "                        similar_words[token.text]=list(set(top_similar_words))\n",
        "            expanded_queries=self.similarwords_replace(query, similar_words)\n",
        "            result.append(expanded_queries)\n",
        "        return result\n",
        "\n",
        "    def remove_punc(self, query: str):\n",
        "        table = str.maketrans(dict.fromkeys(string.punctuation))\n",
        "        title = query.translate(table)\n",
        "        return str(title)\n",
        "\n",
        "    def synonyms(self):\n",
        "        result = []\n",
        "\n",
        "        for query in self.original_query:\n",
        "            new_title = self.remove_punc(query)\n",
        "            syn_pro_title = list()\n",
        "            temp = new_title\n",
        "            new_title = self.nlp(new_title)\n",
        "            for token in new_title:\n",
        "                syn_token = self.find_syns_word(token)\n",
        "                syn_pro_title.extend(\n",
        "                    [syn for syn in list(set(syn_token)) if\n",
        "                     syn != str(token.text)])  # distinct and remove the same words\n",
        "            # print(syn_pro_title)\n",
        "            # synonyms_by_titles.writelines(\" \".join(list(set(syn_pro_title))) + \"\\n\")\n",
        "            # ToDo temp(org) + syns or only syns?\n",
        "            result.append(temp + \" \" + \" \".join(list(set(syn_pro_title))))\n",
        "        return result\n",
        "\n",
        "    def find_syns_word(self, token: str):\n",
        "        syn_token = []\n",
        "        if (token.pos_ == \"NOUN\"):\n",
        "            # ToDo automate wordnet install\n",
        "            for synset in wordnet.synsets(token.lemma_):\n",
        "                for lemma in synset.lemmas()[:self.top_syns]:  # top 5 synonyms\n",
        "                    if \"_\" not in lemma.name():  # not include the words with _ ex: basketball_game\n",
        "                        syn_token.append(lemma.name())\n",
        "                    else:\n",
        "                        for w in lemma.name().split(\"_\"):\n",
        "                            if w not in STOP_WORDS:\n",
        "                                syn_token.append(\n",
        "                                    w)  # add words with _ to two words ex. laptop_computer -> laptop and computer\n",
        "        syn_token = [w for w in syn_token if w != \" \" and len(w) != 0]\n",
        "\n",
        "        # ToDo remove random influence\n",
        "        if len(syn_token) > 5:\n",
        "            return random.sample(syn_token,k=5)  # after top 5 synonyms + splited words -> long titles -> reducing the syns random with 5\n",
        "        else:\n",
        "            return syn_token\n",
        "\n",
        "    def get_comparation_superlation_nouns_from_original_data(self):\n",
        "        result =[]\n",
        "\n",
        "        for query in self.original_query:\n",
        "            nouns_as_string = []\n",
        "            doc = self.nlp(query)\n",
        "            annotations = ['CC', 'CD',\n",
        "                           'JJ', 'JJR', 'JJS',\n",
        "                           'RB', 'RBR', 'RBS',\n",
        "                           'NN', 'NNS', 'NNP', 'NNPS',\n",
        "                           'VB']\n",
        "            for token in doc:\n",
        "                if token.tag_ in annotations:\n",
        "                    nouns_as_string.append(token.text)\n",
        "            result.append(' '.join(nouns_as_string))\n",
        "        return result\n",
        "\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Nl1OoySGmpC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf519fae-76ff-4df4-9026-f834efb17eed"
      },
      "source": [
        "if __name__ == \"__main__\":\n",
        "    query = [\"What is the difference between sex and love?\",\n",
        "             \"Which is the highest mountain in the world?\",\n",
        "             \"Which is better, a laptop or a desktop?\"]\n",
        "\n",
        "    print(\"Org. query:\")\n",
        "\n",
        "    for i in query:\n",
        "        print(i)\n",
        "        \n",
        "    pd.set_option('display.max_columns', 4)\n",
        "    expansion = QueryExpansion(query)\n",
        "    print(\"=====================================================================\")\n",
        "    print(expansion.expansion(original=True,relation=True, synonyms=False, sensevec=True))\n",
        "    print(\"=====================================================================\")\n",
        "    print(expansion.expansion(original=True,relation=True, synonyms=True, embedded=True))\n",
        "    \n",
        "    \n",
        "    expansion.expansion(original=True,relation=True, synonyms=True, embedded=True)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Org. query:\n",
            "What is the difference between sex and love?\n",
            "Which is the highest mountain in the world?\n",
            "Which is better, a laptop or a desktop?\n",
            "=====================================================================\n",
            "                                           topic  \\\n",
            "0   What is the difference between sex and love?   \n",
            "1   What is the difference between sex and love?   \n",
            "2   What is the difference between sex and love?   \n",
            "3   What is the difference between sex and love?   \n",
            "4   What is the difference between sex and love?   \n",
            "5   What is the difference between sex and love?   \n",
            "6   What is the difference between sex and love?   \n",
            "7    Which is the highest mountain in the world?   \n",
            "8    Which is the highest mountain in the world?   \n",
            "9    Which is the highest mountain in the world?   \n",
            "10   Which is the highest mountain in the world?   \n",
            "11   Which is the highest mountain in the world?   \n",
            "12       Which is better, a laptop or a desktop?   \n",
            "13       Which is better, a laptop or a desktop?   \n",
            "14       Which is better, a laptop or a desktop?   \n",
            "15       Which is better, a laptop or a desktop?   \n",
            "16       Which is better, a laptop or a desktop?   \n",
            "\n",
            "                                           expansions  \\\n",
            "0   (original, What is the difference between sex ...   \n",
            "1               (annotation, difference sex and love)   \n",
            "2   (sensevec_1, What is the actual difference bet...   \n",
            "3   (sensevec_2, What is the real difference betwe...   \n",
            "4   (sensevec_3, What is the difference between on...   \n",
            "5   (sensevec_4, What is the difference between ac...   \n",
            "6   (sensevec_5, What is the difference between se...   \n",
            "7   (original, Which is the highest mountain in th...   \n",
            "8                (annotation, highest mountain world)   \n",
            "9   (sensevec_1, Which is the highest canyon in th...   \n",
            "10  (sensevec_2, Which is the highest mountain in ...   \n",
            "11  (sensevec_3, Which is the highest mountain in ...   \n",
            "12  (original, Which is better, a laptop or a desk...   \n",
            "13             (annotation, better laptop or desktop)   \n",
            "14  (sensevec_1, Which is better, a desktop PC or ...   \n",
            "15  (sensevec_2, Which is better, a desktop comput...   \n",
            "16  (sensevec_3, Which is better, a laptop or a Wi...   \n",
            "\n",
            "                                                query         tag  \n",
            "0        What is the difference between sex and love?    original  \n",
            "1                             difference sex and love  annotation  \n",
            "2   What is the actual difference between sex and ...  sensevec_1  \n",
            "3   What is the real difference between sex and love?  sensevec_2  \n",
            "4   What is the difference between only sex and love?  sensevec_3  \n",
            "5   What is the difference between actual sex and ...  sensevec_4  \n",
            "6   What is the difference between sex and real love?  sensevec_5  \n",
            "7         Which is the highest mountain in the world?    original  \n",
            "8                              highest mountain world  annotation  \n",
            "9           Which is the highest canyon in the world?  sensevec_1  \n",
            "10  Which is the highest mountain in the entire wo...  sensevec_2  \n",
            "11  Which is the highest mountain in the whole world?  sensevec_3  \n",
            "12            Which is better, a laptop or a desktop?    original  \n",
            "13                           better laptop or desktop  annotation  \n",
            "14        Which is better, a desktop PC or a desktop?  sensevec_1  \n",
            "15  Which is better, a desktop computer or a desktop?  sensevec_2  \n",
            "16    Which is better, a laptop or a Windows desktop?  sensevec_3  \n",
            "=====================================================================\n",
            "                                           topic  \\\n",
            "0   What is the difference between sex and love?   \n",
            "1   What is the difference between sex and love?   \n",
            "2   What is the difference between sex and love?   \n",
            "3   What is the difference between sex and love?   \n",
            "4    Which is the highest mountain in the world?   \n",
            "5    Which is the highest mountain in the world?   \n",
            "6    Which is the highest mountain in the world?   \n",
            "7    Which is the highest mountain in the world?   \n",
            "8        Which is better, a laptop or a desktop?   \n",
            "9        Which is better, a laptop or a desktop?   \n",
            "10       Which is better, a laptop or a desktop?   \n",
            "11       Which is better, a laptop or a desktop?   \n",
            "12       Which is better, a laptop or a desktop?   \n",
            "13       Which is better, a laptop or a desktop?   \n",
            "\n",
            "                                           expansions  \\\n",
            "0   (original, What is the difference between sex ...   \n",
            "1               (annotation, difference sex and love)   \n",
            "2   (syns, What is the difference between sex and ...   \n",
            "3   (embedded_1, What is the differance between se...   \n",
            "4   (original, Which is the highest mountain in th...   \n",
            "5                (annotation, highest mountain world)   \n",
            "6   (syns, Which is the highest mountain in the wo...   \n",
            "7   (embedded_1, Which is the highest alpine in th...   \n",
            "8   (original, Which is better, a laptop or a desk...   \n",
            "9              (annotation, better laptop or desktop)   \n",
            "10  (syns, Which is better a laptop or a desktop c...   \n",
            "11  (embedded_1, Which is better, a portable or a ...   \n",
            "12  (embedded_2, Which is better, a lap or a deskt...   \n",
            "13  (embedded_3, Which is better, a laptop or a de...   \n",
            "\n",
            "                                                query         tag  \n",
            "0        What is the difference between sex and love?    original  \n",
            "1                             difference sex and love  annotation  \n",
            "2   What is the difference between sex and love di...        syns  \n",
            "3        What is the differance between sex and love?  embedded_1  \n",
            "4         Which is the highest mountain in the world?    original  \n",
            "5                              highest mountain world  annotation  \n",
            "6   Which is the highest mountain in the world dom...        syns  \n",
            "7           Which is the highest alpine in the world?  embedded_1  \n",
            "8             Which is better, a laptop or a desktop?    original  \n",
            "9                            better laptop or desktop  annotation  \n",
            "10  Which is better a laptop or a desktop computer...        syns  \n",
            "11          Which is better, a portable or a desktop?  embedded_1  \n",
            "12               Which is better, a lap or a desktop?  embedded_2  \n",
            "13             Which is better, a laptop or a destop?  embedded_3  \n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}